"""Azure OpenAI åˆ†ææœå‹™æ¨¡çµ„ã€‚

æ­¤æ¨¡çµ„æä¾› Azure OpenAI GPT-4o æ•´åˆåŠŸèƒ½ï¼ŒåŒ…æ‹¬ SEO åˆ†æå ±å‘Šç”Ÿæˆã€
Prompt å·¥ç¨‹ã€Token ç®¡ç†ã€éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶ã€‚
"""

import asyncio
import json
import time
from dataclasses import dataclass
from typing import Dict, Any, Optional, List

from openai import AsyncAzureOpenAI
import openai

from ..config import get_config
from .serp_service import SerpResult
from .scraper_service import ScrapingResult


# è‡ªå®šç¾©ä¾‹å¤–é¡åˆ¥
class AIServiceException(Exception):
    """AI æœå‹™ç›¸é—œéŒ¯èª¤çš„åŸºç¤ä¾‹å¤–é¡åˆ¥ã€‚"""


class TokenLimitExceededException(AIServiceException):
    """Token ä½¿ç”¨é‡è¶…éé™åˆ¶æ™‚çš„ä¾‹å¤–ã€‚"""


class AIAPIException(AIServiceException):
    """Azure OpenAI API å‘¼å«å¤±æ•—æ™‚çš„ä¾‹å¤–ï¼Œå°æ‡‰ API éŒ¯èª¤ç¢¼ AI_API_ERRORã€‚"""


class AITimeoutException(AIServiceException):
    """AI API é€¾æ™‚ä¾‹å¤–ã€‚"""


# è³‡æ–™çµæ§‹å®šç¾©
@dataclass
class AnalysisOptions:
    """SEO åˆ†æé¸é …è³‡æ–™çµæ§‹ã€‚
    
    Attributes:
        generate_draft: æ˜¯å¦ç”Ÿæˆå…§å®¹åˆç¨¿
        include_faq: æ˜¯å¦åŒ…å« FAQ å»ºè­°
        include_table: æ˜¯å¦åŒ…å«æ¯”è¼ƒè¡¨æ ¼
    """
    generate_draft: bool
    include_faq: bool
    include_table: bool


@dataclass
class AnalysisResult:
    """AI åˆ†æçµæœè³‡æ–™çµæ§‹ã€‚
    
    Attributes:
        analysis_report: Markdown æ ¼å¼çš„ SEO åˆ†æå ±å‘Š
        token_usage: AI Token ä½¿ç”¨é‡
        processing_time: AI è™•ç†æ™‚é–“ (ç§’)
        success: æ˜¯å¦æˆåŠŸå®Œæˆåˆ†æ
        error: éŒ¯èª¤è¨Šæ¯ (å¦‚æœæœ‰)
    """
    analysis_report: str
    token_usage: int
    processing_time: float
    success: bool
    error: Optional[str] = None


class AIService:
    """Azure OpenAI åˆ†ææœå‹™é¡åˆ¥ã€‚
    
    æä¾›èˆ‡ Azure OpenAI GPT-4o äº’å‹•çš„å®Œæ•´åŠŸèƒ½ï¼ŒåŒ…æ‹¬ SEO åˆ†æå ±å‘Šç”Ÿæˆã€
    Prompt å·¥ç¨‹ã€Token ç®¡ç†ã€éŒ¯èª¤è™•ç†å’Œé‡è©¦æ©Ÿåˆ¶ã€‚
    """

    def __init__(self):
        """åˆå§‹åŒ– AI æœå‹™ã€‚
        
        è¼‰å…¥ Azure OpenAI é…ç½®ä¸¦å»ºç«‹å®¢æˆ¶ç«¯é€£ç·šã€‚
        """
        self.config = get_config()
        
        # Azure OpenAI é…ç½®åƒæ•¸
        self.api_key = self.config.get_openai_api_key()
        self.endpoint = self.config.get_openai_endpoint()
        self.deployment_name = self.config.get_openai_deployment_name()
        self.api_version = self.config.get_openai_api_version()
        self.model = self.config.get_openai_model()
        self.max_tokens = self.config.get_openai_max_tokens()
        self.temperature = self.config.get_openai_temperature()
        
        # Token ç®¡ç†é…ç½®
        self.max_input_tokens = 6000  # ä¿ç•™ 2000 tokens çµ¦å›æ‡‰
        self.max_retries = 3
        self.retry_delay = 2.0
        
        # åˆå§‹åŒ– Azure OpenAI å®¢æˆ¶ç«¯
        self.client = AsyncAzureOpenAI(
            api_key=self.api_key,
            api_version=self.api_version,
            azure_endpoint=self.endpoint,
        )
    
    async def analyze_seo_content(
        self,
        keyword: str,
        audience: str,
        serp_data: SerpResult,
        scraping_data: ScrapingResult,
        options: AnalysisOptions
    ) -> AnalysisResult:
        """åŸ·è¡Œå®Œæ•´çš„ SEO å…§å®¹åˆ†æã€‚
        
        çµåˆ SERP è³‡æ–™å’Œçˆ¬èŸ²å…§å®¹ï¼Œä½¿ç”¨ GPT-4o ç”Ÿæˆå°ˆæ¥­çš„ SEO åˆ†æå ±å‘Šã€‚
        
        Args:
            keyword: ç›®æ¨™é—œéµå­—
            audience: ç›®æ¨™å—çœ¾æè¿°
            serp_data: SERP æœå°‹çµæœè³‡æ–™
            scraping_data: ç¶²é çˆ¬èŸ²å…§å®¹è³‡æ–™
            options: åˆ†æé¸é …è¨­å®š
            
        Returns:
            AnalysisResult: åŒ…å«åˆ†æå ±å‘Šå’Œçµ±è¨ˆè³‡è¨Šçš„çµæœ
            
        Raises:
            AIServiceException: AI æœå‹™åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤
            TokenLimitExceededException: Token ä½¿ç”¨é‡è¶…éé™åˆ¶
            AIAPIException: Azure OpenAI API å‘¼å«å¤±æ•—
        """
        start_time = time.time()
        
        try:
            # å»ºç«‹åˆ†ææç¤º
            prompt = self._build_analysis_prompt(
                keyword=keyword,
                audience=audience,
                serp_data=serp_data,
                scraping_data=scraping_data,
                options=options
            )
            
            # å°å‡ºé€çµ¦AIçš„å…§å®¹ï¼ˆé™åˆ¶é•·åº¦é¿å…éé•·ï¼‰
            prompt_preview = prompt[:500] + '...' if len(prompt) > 500 else prompt
            print("ğŸ¤– é€çµ¦AIçš„æç¤ºå…§å®¹ï¼š")
            print(f"   é•·åº¦: {len(prompt)} å­—å…ƒ")
            print(f"   å…§å®¹é è¦½: {prompt_preview}")
            print()
            
            # é©—è­‰ Token ä½¿ç”¨é‡
            if not self._validate_token_usage(prompt):
                # æˆªæ–·å…§å®¹å¾Œé‡æ–°å»ºç«‹æç¤º
                truncated_scraping = self._truncate_scraping_content(scraping_data)
                prompt = self._build_analysis_prompt(
                    keyword=keyword,
                    audience=audience,
                    serp_data=serp_data,
                    scraping_data=truncated_scraping,
                    options=options
                )
                
                if not self._validate_token_usage(prompt):
                    raise TokenLimitExceededException(
                        f"å³ä½¿æˆªæ–·å…§å®¹å¾Œï¼ŒToken ä½¿ç”¨é‡ä»è¶…é {self.max_input_tokens} é™åˆ¶"
                    )
            
            # å‘¼å« Azure OpenAI API
            api_response = await self._call_openai_api_with_retry(prompt)
            
            # è§£æå›æ‡‰
            analysis_report = self._parse_openai_response(api_response)
            token_usage = api_response.get('usage', {}).get('total_tokens', 0)
            
            # å°å‡ºAIå›è¦†çµæœ
            report_preview = analysis_report[:500] + '...' if len(analysis_report) > 500 else analysis_report
            print("ğŸ¤– AI å›è¦†çµæœï¼š")
            print(f"   é•·åº¦: {len(analysis_report)} å­—å…ƒ")
            print(f"   Tokenä½¿ç”¨: {token_usage}")
            print(f"   å…§å®¹é è¦½: {report_preview}")
            print()
            
            processing_time = time.time() - start_time
            
            return AnalysisResult(
                analysis_report=analysis_report,
                token_usage=token_usage,
                processing_time=processing_time,
                success=True
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            error_message = str(e)
            
            # æ ¹æ“šä¾‹å¤–é¡å‹åˆ†é¡è™•ç†
            if isinstance(e, (TokenLimitExceededException, AIAPIException, AITimeoutException)):
                raise e
            else:
                raise AIServiceException(f"AI åˆ†æåŸ·è¡Œå¤±æ•—: {error_message}")
    
    def _build_analysis_prompt(
        self,
        keyword: str,
        audience: str,
        serp_data: SerpResult,
        scraping_data: ScrapingResult,
        options: AnalysisOptions
    ) -> str:
        """å»ºç«‹å®Œæ•´çš„åˆ†ææç¤ºã€‚
        
        æ•´åˆæ‰€æœ‰è¼¸å…¥è³‡æ–™ï¼Œå»ºç«‹çµæ§‹åŒ–çš„ GPT-4o åˆ†ææç¤ºã€‚
        
        Args:
            keyword: ç›®æ¨™é—œéµå­—
            audience: ç›®æ¨™å—çœ¾
            serp_data: SERP è³‡æ–™
            scraping_data: çˆ¬èŸ²è³‡æ–™
            options: åˆ†æé¸é …
            
        Returns:
            str: å®Œæ•´çš„åˆ†ææç¤º
        """
        prompt_parts = [
            self._get_system_prompt(),
            self._format_analysis_request(keyword, audience),
            self._format_serp_data(serp_data),
            self._format_scraping_data(scraping_data),
            self._format_options_requirements(options),
            self._get_output_format_requirements()
        ]
        
        return "\n\n".join(prompt_parts)
    
    def _get_system_prompt(self) -> str:
        """å–å¾—ç³»çµ±æç¤ºï¼Œå®šç¾© AI çš„è§’è‰²å’Œä»»å‹™ã€‚"""
        return """ä½ æ˜¯ä¸€ä½è³‡æ·±çš„ SEO å°ˆå®¶å’Œå…§å®¹ç­–ç•¥å¸«ï¼Œæ“æœ‰è¶…é 10 å¹´çš„æœå°‹å¼•æ“å„ªåŒ–ç¶“é©—ã€‚

## ä½ çš„å°ˆæ¥­èƒ½åŠ›ï¼š
1. æ·±åº¦åˆ†æ SERP (æœå°‹å¼•æ“çµæœé é¢) ç«¶çˆ­å°æ‰‹ç­–ç•¥
2. è­˜åˆ¥é—œéµå­—æ„åœ–å’Œæœå°‹è¶¨å‹¢
3. æä¾›å…·é«”å¯åŸ·è¡Œçš„ SEO å„ªåŒ–å»ºè­°
4. è¨­è¨ˆç¬¦åˆç›®æ¨™å—çœ¾éœ€æ±‚çš„å…§å®¹ç­–ç•¥

## ä½ çš„ä»»å‹™ï¼š
åŸºæ–¼æä¾›çš„çœŸå¯¦ SERP è³‡æ–™å’Œç«¶çˆ­å°æ‰‹é é¢å…§å®¹åˆ†æï¼Œç‚ºæŒ‡å®šé—œéµå­—å’Œç›®æ¨™å—çœ¾ç”Ÿæˆå°ˆæ¥­ã€å¯¦ç”¨çš„ SEO åˆ†æå ±å‘Šã€‚

## åˆ†æåŸå‰‡ï¼š
- åŸºæ–¼å¯¦éš›è³‡æ–™ï¼Œé¿å…æ³›æ³›è€Œè«‡
- æä¾›å…·é«”çš„å„ªåŒ–å»ºè­°å’Œè¡Œå‹•æ–¹æ¡ˆ
- è€ƒæ…®ç›®æ¨™å—çœ¾çš„æœå°‹æ„åœ–å’Œéœ€æ±‚
- è­˜åˆ¥å¸‚å ´ç«¶çˆ­ç©ºç™½é»å’Œæ©Ÿæœƒ"""
    
    def _format_analysis_request(self, keyword: str, audience: str) -> str:
        """æ ¼å¼åŒ–åˆ†æè«‹æ±‚è³‡è¨Šã€‚"""
        return f"""## åˆ†æä»»å‹™

**ç›®æ¨™é—œéµå­—**: {keyword}
**ç›®æ¨™å—çœ¾**: {audience}

è«‹é‡å°æ­¤é—œéµå­—å’Œå—çœ¾ï¼ŒåŸºæ–¼ä»¥ä¸‹æä¾›çš„çœŸå¯¦è³‡æ–™é€²è¡Œæ·±åº¦ SEO åˆ†æã€‚"""
    
    def _format_serp_data(self, serp_data: SerpResult) -> str:
        """æ ¼å¼åŒ– SERP è³‡æ–™ç‚ºæç¤ºå…§å®¹ã€‚"""
        serp_text = f"""## SERP è³‡æ–™åˆ†æ

**æœå°‹é—œéµå­—**: {serp_data.keyword}
**ç¸½æœå°‹çµæœæ•¸**: {serp_data.total_results:,}
**åˆ†ææ¨£æœ¬æ•¸**: {len(serp_data.organic_results)}

### å‰ {len(serp_data.organic_results)} åç«¶çˆ­å°æ‰‹ï¼š
"""
        
        for result in serp_data.organic_results:
            serp_text += f"""
**ç¬¬ {result.position} å**:
- æ¨™é¡Œ: {result.title}
- URL: {result.link}
- æè¿°: {result.snippet}
"""
        
        if serp_data.related_searches:
            serp_text += f"\n### ç›¸é—œæœå°‹å»ºè­°:\n"
            for i, related in enumerate(serp_data.related_searches[:5], 1):
                serp_text += f"{i}. {related}\n"
        
        return serp_text
    
    def _format_scraping_data(self, scraping_data: ScrapingResult) -> str:
        """æ ¼å¼åŒ–çˆ¬èŸ²è³‡æ–™ç‚ºæç¤ºå…§å®¹ã€‚"""
        scraping_text = f"""## ç«¶çˆ­å°æ‰‹é é¢å…§å®¹åˆ†æ

**çˆ¬å–çµ±è¨ˆ**:
- ç¸½é é¢æ•¸: {scraping_data.total_results}
- æˆåŠŸçˆ¬å–: {scraping_data.successful_scrapes}
- å¹³å‡å­—æ•¸: {scraping_data.avg_word_count}
- å¹³å‡æ®µè½æ•¸: {scraping_data.avg_paragraphs}

### æˆåŠŸçˆ¬å–çš„é é¢è©³ç´°å…§å®¹:
"""
        
        successful_pages = [page for page in scraping_data.pages if page.success]
        
        for i, page in enumerate(successful_pages[:5], 1):  # é™åˆ¶æœ€å¤š 5 å€‹é é¢
            scraping_text += f"""
**é é¢ {i}**: {page.url}
- æ¨™é¡Œ: {page.title or 'æœªå–å¾—'}
- Meta æè¿°: {page.meta_description or 'æœªå–å¾—'}
- H1: {page.h1 or 'æœªå–å¾—'}
- H2 æ¨™ç±¤ ({len(page.h2_list)} å€‹): {', '.join(page.h2_list[:10])}{'...' if len(page.h2_list) > 10 else ''}
- å­—æ•¸: {page.word_count}, æ®µè½æ•¸: {page.paragraph_count}
"""
        
        return scraping_text
    
    def _format_options_requirements(self, options: AnalysisOptions) -> str:
        """æ ¹æ“šé¸é …æ ¼å¼åŒ–é¡å¤–éœ€æ±‚ã€‚"""
        requirements = ["## ç‰¹æ®Šè¦æ±‚"]
        
        if options.generate_draft:
            requirements.append("- ç”Ÿæˆå…§å®¹åˆç¨¿å»ºè­°")
        
        if options.include_faq:
            requirements.append("- åŒ…å« FAQ å»ºè­°")
        
        if options.include_table:
            requirements.append("- åŒ…å«æ¯”è¼ƒåˆ†æè¡¨æ ¼")
        
        return "\n".join(requirements)
    
    def _get_output_format_requirements(self) -> str:
        """å–å¾—è¼¸å‡ºæ ¼å¼è¦æ±‚ã€‚"""
        return """## è¼¸å‡ºæ ¼å¼è¦æ±‚

è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¼¸å‡ºå®Œæ•´çš„ SEO åˆ†æå ±å‘Šï¼š

# SEO åˆ†æå ±å‘Š

## 1. åˆ†ææ¦‚è¿°
- é—œéµå­—æœå°‹æ„åœ–åˆ†æ
- å¸‚å ´ç«¶çˆ­æ¿€çƒˆç¨‹åº¦è©•ä¼°
- ç›®æ¨™å—çœ¾åŒ¹é…åº¦åˆ†æ

## 2. SERP åˆ†æçµæœ
- å‰ 5 åç«¶çˆ­å°æ‰‹ç­–ç•¥è§£æ
- æ¨™é¡Œé•·åº¦å’Œé—œéµå­—ä½¿ç”¨æ¨¡å¼
- æè¿°ç‰‡æ®µæ’°å¯«ç­–ç•¥
- ç¶²åŸŸæ¬Šå¨åº¦è§€å¯Ÿ

## 3. å…§å®¹ç­–ç•¥å»ºè­°
- æ¨è–¦æ¨™é¡Œå¯«æ³• (3-5 å€‹é¸é …)
- Meta æè¿°æ’°å¯«å»ºè­°
- å…§å®¹çµæ§‹è¦åŠƒ (H1, H2, H3)
- ç›®æ¨™å­—æ•¸å»ºè­°

## 4. é—œéµå­—ç­–ç•¥
- ä¸»è¦é—œéµå­—å„ªåŒ–å»ºè­°
- ç›¸é—œé—œéµå­—æ“´å±•
- é•·å°¾é—œéµå­—æ©Ÿæœƒ
- èªç¾©ç›¸é—œè©å½™å»ºè­°

## 5. ç«¶çˆ­å„ªå‹¢åˆ†æ
- å…§å®¹å·®ç•°åŒ–æ©Ÿæœƒ
- ç«¶çˆ­å°æ‰‹å¼±é»åˆ†æ
- å¸‚å ´ç©ºç™½é»è­˜åˆ¥
- è¶…è¶Šç«¶çˆ­å°æ‰‹çš„ç­–ç•¥

## 6. åŸ·è¡Œå»ºè­°
- å„ªå…ˆåŸ·è¡Œé …ç›® (å‰ 3 é …)
- å…§å®¹å‰µä½œæ™‚ç¨‹è¦åŠƒ
- æ•ˆæœè©•ä¼°æŒ‡æ¨™
- å¾ŒçºŒå„ªåŒ–å»ºè­°

[æ ¹æ“šé¸é …åŒ…å«é¡å¤–å…§å®¹ï¼šåˆç¨¿å»ºè­°ã€FAQã€æ¯”è¼ƒè¡¨æ ¼]

**é‡è¦**: æ‰€æœ‰å»ºè­°å¿…é ˆåŸºæ–¼æä¾›çš„çœŸå¯¦è³‡æ–™ï¼Œé¿å…æ³›æ³›è€Œè«‡ã€‚æ¯å€‹å»ºè­°éƒ½è¦å…·é«”å¯åŸ·è¡Œã€‚"""
    
    def _validate_token_usage(self, prompt: str) -> bool:
        """é©—è­‰ Token ä½¿ç”¨é‡æ˜¯å¦åœ¨é™åˆ¶ç¯„åœå…§ã€‚
        
        Args:
            prompt: è¦æª¢æŸ¥çš„æç¤ºæ–‡å­—
            
        Returns:
            bool: æ˜¯å¦åœ¨é™åˆ¶ç¯„åœå…§
        """
        estimated_tokens = self._estimate_token_count(prompt)
        return estimated_tokens <= self.max_input_tokens
    
    def _estimate_token_count(self, text: str) -> int:
        """ä¼°ç®—æ–‡å­—çš„ Token ä½¿ç”¨é‡ã€‚
        
        ä½¿ç”¨ç°¡åŒ–çš„ä¼°ç®—æ–¹æ³•ï¼šä¸­è‹±æ–‡æ··åˆæ–‡å­—ç´„ 3 å­—å…ƒ/tokenã€‚
        
        Args:
            text: è¦ä¼°ç®—çš„æ–‡å­—
            
        Returns:
            int: ä¼°ç®—çš„ Token æ•¸é‡
        """
        return len(text.encode('utf-8')) // 3
    
    def _truncate_scraping_content(self, scraping_data: ScrapingResult) -> ScrapingResult:
        """æˆªæ–·çˆ¬èŸ²å…§å®¹ä»¥ç¬¦åˆ Token é™åˆ¶ã€‚
        
        å„ªå…ˆä¿ç•™æˆåŠŸçˆ¬å–çš„é é¢ï¼Œä¸¦æˆªæ–·éé•·çš„å…§å®¹ã€‚
        
        Args:
            scraping_data: åŸå§‹çˆ¬èŸ²è³‡æ–™
            
        Returns:
            ScrapingResult: æˆªæ–·å¾Œçš„çˆ¬èŸ²è³‡æ–™
        """
        # å»ºç«‹æˆªæ–·ç‰ˆæœ¬ï¼Œåªä¿ç•™å‰ 3 å€‹æˆåŠŸé é¢
        successful_pages = [page for page in scraping_data.pages if page.success][:3]
        
        # æˆªæ–·æ¯å€‹é é¢çš„ H2 æ¸…å–®
        for page in successful_pages:
            if len(page.h2_list) > 5:
                page.h2_list = page.h2_list[:5]
        
        return ScrapingResult(
            total_results=scraping_data.total_results,
            successful_scrapes=len(successful_pages),
            avg_word_count=scraping_data.avg_word_count,
            avg_paragraphs=scraping_data.avg_paragraphs,
            pages=successful_pages,
            errors=scraping_data.errors
        )
    
    async def _call_openai_api_with_retry(self, prompt: str) -> Dict[str, Any]:
        """å‘¼å« Azure OpenAI API ä¸¦åŒ…å«é‡è©¦æ©Ÿåˆ¶ã€‚
        
        Args:
            prompt: åˆ†ææç¤º
            
        Returns:
            dict: OpenAI API å›æ‡‰
            
        Raises:
            AIAPIException: API å‘¼å«å¤±æ•—
            AITimeoutException: API å‘¼å«é€¾æ™‚
        """
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                return await self._call_openai_api(prompt)
                
            except openai.RateLimitError as e:
                last_error = AIAPIException(f"API é€Ÿç‡é™åˆ¶: {str(e)}")
                if attempt < self.max_retries - 1:
                    delay = self.retry_delay * (2 ** attempt)  # æŒ‡æ•¸é€€é¿
                    await asyncio.sleep(delay)
                    continue
                    
            except openai.APITimeoutError as e:
                last_error = AITimeoutException(f"API é€¾æ™‚: {str(e)}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(self.retry_delay)
                    continue
                    
            except openai.APIError as e:
                last_error = AIAPIException(f"API éŒ¯èª¤: {str(e)}")
                break  # API éŒ¯èª¤ä¸é‡è©¦
                
            except Exception as e:
                last_error = AIServiceException(f"æœªé æœŸéŒ¯èª¤: {str(e)}")
                break
        
        # æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
        if last_error:
            raise last_error
        else:
            raise AIAPIException("Azure OpenAI API å‘¼å«å¤±æ•—")
    
    async def _call_openai_api(self, prompt: str) -> Dict[str, Any]:
        """å¯¦éš›å‘¼å« Azure OpenAI APIã€‚
        
        Args:
            prompt: åˆ†ææç¤º
            
        Returns:
            dict: OpenAI API å®Œæ•´å›æ‡‰
        """
        response = await self.client.chat.completions.create(
            model=self.deployment_name,
            messages=[
                {"role": "user", "content": prompt}
            ],
            max_tokens=self.max_tokens - self._estimate_token_count(prompt),
            temperature=self.temperature,
            stream=False
        )
        
        # è½‰æ›ç‚ºå­—å…¸æ ¼å¼ä»¥ä¾¿è™•ç†
        # å®‰å…¨åœ°å­˜å–å¯èƒ½ç‚º None çš„å±¬æ€§
        content = response.choices[0].message.content if response.choices[0].message.content else ""
        
        usage_data = {
            'total_tokens': 0,
            'prompt_tokens': 0,
            'completion_tokens': 0
        }
        
        if response.usage is not None:
            usage_data = {
                'total_tokens': response.usage.total_tokens or 0,
                'prompt_tokens': response.usage.prompt_tokens or 0,
                'completion_tokens': response.usage.completion_tokens or 0
            }
        
        return {
            'choices': [{'message': {'content': content}}],
            'usage': usage_data
        }
    
    def _parse_openai_response(self, response: Dict[str, Any]) -> str:
        """è§£æ OpenAI API å›æ‡‰ã€‚
        
        Args:
            response: OpenAI API å›æ‡‰
            
        Returns:
            str: è§£æå‡ºçš„åˆ†æå ±å‘Š
            
        Raises:
            AIServiceException: å›æ‡‰è§£æå¤±æ•—
        """
        try:
            content = response['choices'][0]['message']['content']
            
            if not content or not isinstance(content, str):
                raise AIServiceException("OpenAI API å›æ‡‰å…§å®¹ç‚ºç©ºæˆ–æ ¼å¼éŒ¯èª¤")
            
            # æ¸…ç†å›æ‡‰å…§å®¹
            content = content.strip()
            
            # ä¿®æ­£ Markdown è¡¨æ ¼æ ¼å¼
            content = self._fix_markdown_table_formatting(content)
            
            # é©—è­‰æ˜¯å¦åŒ…å«å¿…è¦çš„å ±å‘Šçµæ§‹
            required_sections = ['# SEO åˆ†æå ±å‘Š', '## 1. åˆ†ææ¦‚è¿°', '## 2. SERP åˆ†æçµæœ']
            for section in required_sections:
                if section not in content:
                    print(f"è­¦å‘Šï¼šå›æ‡‰ç¼ºå°‘å¿…è¦ç« ç¯€ '{section}'")
            
            return content
            
        except (KeyError, IndexError, TypeError) as e:
            raise AIServiceException(f"OpenAI API å›æ‡‰è§£æå¤±æ•—: {str(e)}")
    
    def _fix_markdown_table_formatting(self, content: str) -> str:
        """ä¿®æ­£ Markdown è¡¨æ ¼æ ¼å¼ï¼Œç¢ºä¿æ­£ç¢ºçš„æ›è¡Œã€‚
        
        Args:
            content: åŸå§‹ Markdown å…§å®¹
            
        Returns:
            str: ä¿®æ­£å¾Œçš„ Markdown å…§å®¹
        """
        import re
        
        # ç¬¬ä¸€æ­¥ï¼šåœ¨ ### æ¨™é¡Œå¾Œç¢ºä¿æœ‰å…©å€‹æ›è¡Œ
        content = re.sub(r'(###[^\n]*)\n([|])', r'\1\n\n\2', content)
        
        # ç¬¬äºŒæ­¥ï¼šè™•ç†è¡¨æ ¼è¡Œé–“çš„æ›è¡Œ - ç¢ºä¿è¡¨æ ¼å…§æ¯ä¸€è¡Œå¾Œéƒ½æœ‰ \n\n
        # æ‰¾åˆ°æ‰€æœ‰è¡¨æ ¼è¡Œï¼ˆä»¥ | é–‹é ­å’Œçµå°¾çš„è¡Œï¼‰
        lines = content.split('\n')
        fixed_lines = []
        
        i = 0
        while i < len(lines):
            line = lines[i]
            fixed_lines.append(line)
            
            # å¦‚æœé€™æ˜¯è¡¨æ ¼è¡Œ
            if line.strip().startswith('|') and line.strip().endswith('|'):
                # æª¢æŸ¥ä¸‹ä¸€è¡Œ
                if i + 1 < len(lines):
                    next_line = lines[i + 1] if i + 1 < len(lines) else ""
                    
                    # å¦‚æœä¸‹ä¸€è¡Œæ˜¯è¡¨æ ¼è¡Œï¼Œç¢ºä¿è¡Œé–“æœ‰ \n\n
                    if next_line.strip().startswith('|') and next_line.strip().endswith('|'):
                        fixed_lines.append('')  # æ·»åŠ ç©ºè¡Œï¼Œå½¢æˆ \n\n
                    # å¦‚æœä¸‹ä¸€è¡Œä¸æ˜¯è¡¨æ ¼è¡Œä½†æœ‰å…§å®¹ï¼Œä¹Ÿè¦ç¢ºä¿æœ‰ \n\n
                    elif next_line.strip() and not next_line.startswith('#'):
                        fixed_lines.append('')  # æ·»åŠ ç©ºè¡Œ
            
            i += 1
        
        fixed_content = '\n'.join(fixed_lines)
        
        # ç¬¬ä¸‰æ­¥ï¼šç§»é™¤éå¤šçš„é€£çºŒç©ºè¡Œï¼ˆè¶…é2å€‹ï¼‰
        fixed_content = re.sub(r'\n{3,}', '\n\n', fixed_content)
        
        return fixed_content

    async def _test_connection(self) -> bool:
        """æ¸¬è©¦ Azure OpenAI é€£ç·šç‹€æ…‹
        
        ä½¿ç”¨æœ€å° token çš„æ¸¬è©¦è«‹æ±‚é©—è­‰é€£ç·šã€‚
        
        Returns:
            bool: é€£ç·šæ˜¯å¦æˆåŠŸ
            
        Raises:
            AIServiceException: ç•¶ API é€£ç·šå¤±æ•—æ™‚
        """
        try:
            if not self.api_key or not self.endpoint:
                raise AIServiceException("Azure OpenAI not configured")
            
            client = AsyncAzureOpenAI(
                api_key=self.api_key,
                api_version="2024-02-01",
                azure_endpoint=self.endpoint
            )
            
            # ç™¼é€æœ€å°çš„æ¸¬è©¦è«‹æ±‚ (ç´„ 10-20 tokens)
            response = await client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1,
                timeout=10.0
            )
            
            return True
            
        except openai.AuthenticationError:
            raise AIServiceException("Invalid Azure OpenAI credentials")
        except openai.APITimeoutError:
            raise AIServiceException("Azure OpenAI request timeout")
        except openai.APIConnectionError:
            raise AIServiceException("Azure OpenAI connection failed")
        except Exception as e:
            if isinstance(e, AIServiceException):
                raise
            raise AIServiceException(f"Connection test failed: {str(e)}")


# å…¨åŸŸæœå‹™å¯¦ä¾‹
_ai_service = None


def get_ai_service() -> AIService:
    """å–å¾— AI æœå‹™çš„å…¨åŸŸå¯¦ä¾‹ã€‚
    
    å¯¦ä½œå–®ä¾‹æ¨¡å¼ï¼Œç¢ºä¿æ•´å€‹æ‡‰ç”¨ç¨‹å¼ä½¿ç”¨åŒä¸€å€‹æœå‹™å¯¦ä¾‹ã€‚
    
    Returns:
        AIService: AI æœå‹™å¯¦ä¾‹
    """
    global _ai_service
    if _ai_service is None:
        _ai_service = AIService()
    return _ai_service